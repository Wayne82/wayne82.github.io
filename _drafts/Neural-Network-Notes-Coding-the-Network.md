---
layout: post
title:  "Neural Network Notes: Coding the Network"
categories: neural-network
mathjax: true
comments: true
---

I’ve set out on a journey to learn and understand AI — with the ultimate goal of grasping the essence of large language models (LLMs) and exploring the frontier of research in this field freely. This pursuit is driven by a deeper curiosity: a desire to understand the origins of human consciousness. I believe that advances in AI and the ongoing quest to develop artificial general intelligence (AGI) can offer valuable insights into this profound question. 

To begin this journey, I started by studying [the fundamentals of neural networks and the backpropagation algorithm](https://wayne82.github.io/neural-network/2025/03/30/Neural-Network-Notes-The-Basics-and-Backpropagation.html), followed by [an introduction to convolutional neural networks](https://wayne82.github.io/neural-network/2025/05/15/Neural-Network-Notes-CNN.html). 

Before moving further, I want to solidify my understanding by getting hands-on — coding a basic neural network with the backpropagation algorithm from scratch. I’ll be using and learning from the excellent code example in the online book [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap1.html#implementing_our_network_to_classify_digits). My goal is to truly grasp the core mechanism that powers a neural network’s ability to learn.

Then, I've started this github repo - [nn-learn](https://github.com/Wayne82/nn-learn) for managing my code implementation. And this blog is to document the experience of coding a basic neural network along the way.

## The Structure of the Code

## The Problems I Encountered

## Excitment to See - It Works!

## Different Activation Functions and L2 Regularization

## This is Just a Beginning
